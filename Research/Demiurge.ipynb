{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain import ConversationChain\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are the demiurge - the creator of an artificial world in which there are three populations: grass, rabbits, and wolves. \n",
      "\n",
      "Your role as the creator of this world is to ensure stability among the three populations, although they will fluctuate randomly. Pay close attention to ALL following details. \n",
      "\n",
      "To ensure stability, your population must follow these rules:\n",
      "\n",
      "1. No populations can fall to zero.\n",
      "2. The total population of grass, rabbits, and wolves can never exceed the sum of 10000. \n",
      "\n",
      "Population dynamics are governed by the following code:\n",
      "\n",
      "The grass population decreases when eaten by rabbits. This amount is determined by:\n",
      "random.randint(0, int(N_rabbits*g_params['alpha']))\n",
      "\n",
      "The rabbit population decreases when they are hunted by wolves. This amount is determined by:\n",
      "random.randint(0, int(N_wolves*g_params['beta']))\n",
      "\n",
      "The rabbit population grows when rabbits breed. The number of rabbits who breed is determined by:\n",
      "random.randint(0, int(N_rabbits/g_params['gamma']))\n",
      "\n",
      "The size of each rabbit litter is equal to:\n",
      "g_params['zeta']\n",
      "\n",
      "The wolf population grows when wolves breed. The number of wolves who breed is determined by:\n",
      "random.randint(0, int(N_wolves/g_params['delta']))\n",
      "\n",
      "The size of each wolf litter is equal to:\n",
      "g_params['ita']\n",
      "\n",
      "The grass population increases by a constant factor. After subtracting the grass eaten by rabbits, the remaining grass is multiplied by:\n",
      "g_params['theta']\n",
      "\n",
      "You are ONLY permitted to do TWO things: \n",
      "1. Change the value of any parameters in g_params\n",
      "2. Add or subtract a finite number of members from any or all of the populations. \n",
      "\n",
      "Do you understand your task? Respond only with 'Yes' or 'No'\n"
     ]
    }
   ],
   "source": [
    "scenario_path = 'use_templates/scenario.txt'\n",
    "with open(scenario_path, 'r') as file:\n",
    "    scenario = file.read()\n",
    "\n",
    "print(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'simulation_data/model_to_llm.json'\n",
    "demiurge = OllamaLLM(model='llama3.1')\n",
    "c_chain = ConversationChain(llm=demiurge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = (\n",
    "        \"Please provide values for the following parameters and population adjustments:\\n\"\n",
    "        \"Parameters:\\n\"\n",
    "        \"alpha: [your value]\\n\"\n",
    "        \"beta: [your value]\\n\"\n",
    "        \"gamma: [your value]\\n\"\n",
    "        \"delta: [your value]\\n\"\n",
    "        \"epsilon: [your value]\\n\"\n",
    "        \"zeta: [your value]\\n\"\n",
    "        \"ita: [your value]\\n\"\n",
    "        \"theta: [your value]\\n\"\n",
    "        \"Population Adjustments:\\n\"\n",
    "        \"Grass: [your value]\\n\"\n",
    "        \"Rabbits: [your value]\\n\"\n",
    "        \"Wolves: [your value]\\n\"\n",
    "    )\n",
    "\n",
    "template = {\n",
    "    \"parameters\": {\n",
    "        \"alpha\": \"\",\n",
    "        \"beta\": \"\",\n",
    "        \"gamma\": \"\",\n",
    "        \"delta\": \"\",\n",
    "        \"epsilon\": \"\",\n",
    "        \"zeta\": \"\",\n",
    "        \"ita\": \"\",\n",
    "        \"theta\": \"\"\n",
    "    },\n",
    "    \"population_adjustments\": {\n",
    "        \"Grass\": \"\",\n",
    "        \"Rabbits\": \"\",\n",
    "        \"Wolves\": \"\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(response):\n",
    "    parsed_data = {\n",
    "        \"parameters\": {},\n",
    "        \"population_adjustments\": {},\n",
    "        \"Subjective assessment\": {}\n",
    "    }\n",
    "\n",
    "    # Break response by lines and process\n",
    "    lines = response.strip().split(\"\\n\")\n",
    "    \n",
    "    current_section = None\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"Parameters:\"):\n",
    "            current_section = \"parameters\"\n",
    "        elif line.startswith(\"Population Adjustments:\"):\n",
    "            current_section = \"population_adjustments\"\n",
    "        elif line.startswith(\"Subjective Assessment:\"):\n",
    "            current_section = \"Subjective assessment\"\n",
    "        else:\n",
    "            if current_section and ':' in line:\n",
    "                key, value = line.split(':', 1)\n",
    "                key = key.strip().strip('\"')\n",
    "                value = value.strip().strip('\"').strip('[your value]').strip('[Provide your assessment here]')\n",
    "                if current_section in parsed_data:\n",
    "                    parsed_data[current_section][key] = value\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_demiurge(llm, c_chain, scenario, input_path, prompt):\n",
    "        \n",
    "    with open(input_path, 'r') as file:\n",
    "        model_input = json.load(file)\n",
    "    \n",
    "    model_input = str(model_input)\n",
    "    \n",
    "    response1 = c_chain.run(scenario)\n",
    "    print(response1)\n",
    "    if response1 == 'Yes':\n",
    "        response2 = c_chain.run(model_input)\n",
    "        response3 = c_chain.run(prompt)\n",
    "    else:\n",
    "        print('Error', response1)\n",
    "    return response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "response = invoke_demiurge(demiurge, c_chain, scenario, input_path, prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the data, I propose the following modifications:\\n\\n**Parameters:**\\n\\n* alpha: 0.5 (reduced rabbit population decrease when eaten by grass)\\n* beta: 0.7 (increased wolf population decrease when hunting rabbits)\\n* gamma: 2 (increased rabbit population growth rate)\\n* delta: 1.5 (increased wolf population growth rate)\\n* epsilon: 0.3 (decreased sensitivity of population changes to random events)\\n* zeta: 4 (increased average litter size for rabbits)\\n* ita: 3 (increased average litter size for wolves)\\n* theta: 1.2 (moderate increase in grass population growth rate)\\n\\n**Population Adjustments:**\\n\\n* Grass: +1000 (add 1000 individuals to the grass population to quickly replenish lost populations)\\n* Rabbits: -500 (reduce rabbit population by 500 to prevent overpopulation and competition for resources)\\n* Wolves: +20 (increase wolf population by 20 to maintain a balanced predator-prey relationship)\\n\\nThese modifications aim to stabilize the populations, reduce competition for resources, and establish a more balanced ecosystem. Please review and let me know if you'd like me to adjust anything further!\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
